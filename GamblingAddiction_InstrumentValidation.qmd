---
title: "Initiation and Sustenance of Quitting Gambling "
author: "Miguel Fudolig"
format: html
editor: visual
---

```{r,intro}
#| output: false
library(here)
library(tidyverse)
library(corrplot)
library(semTools)
library(lavaanPlot)
library(tidySEM)
library(semPlot)
library(ltm)
library(psych)
```

## Testing Construct Validity

We test the construct validity using the Confirmatory Factor Analysis to show that the instrument is valid across problem and non-problem gamblers. The CFA is related to the measurement side of the Structural Equation Modeling framework and is sufficient in proving instrument validity.

## Loading in the Dataset

I am loading the recoded dataset that you provided me into R.

```{r}

gambling <- read.csv("Gambling behavior among college students_RECODED.csv") |> as_tibble()

gambling <- gambling |> mutate(Gambled = ifelse(GambleD==0,0,1))
```

I introduced a new variable named Gambled, where Gambled=0 corresponds to whether the participant gambled within the past 30 days. Else, Gambled=1.

## Summary statistics of the scores

Let's look at the summary statistics of the scores first.

```{r, summary}

gambling |> summarize(PA_mean = mean(PA),
                      PA_sd = sd(PA),
                      PA_median=as.numeric(quantile(PA,0.5)),
                      PAD_mean = mean(PAD),
                      PAD_sd = sd(PAD),
                      PAD_median=as.numeric(quantile(PAD,0.5)),
                      PD_mean = mean(PD),
                      PD_sd = sd(PD),
                      PD_median=as.numeric(quantile(PD,0.5)),
                      BC_mean = mean(BC),
                      BC_sd = sd(BC),
                      BC_median=as.numeric(quantile(BC,0.5)),
                      CPE_mean = mean(CPE),
                      CPE_sd = sd(CPE),
                      CPE_median=as.numeric(quantile(CPE,0.5)),
                      ET_mean = mean(ET),
                      ET_sd = sd(ET),
                      ET_median=as.numeric(quantile(ET,0.5)),
                      PfC_mean = mean(PfC),
                      PfC_sd = sd(PfC),
                      PfC_median=as.numeric(quantile(PfC,0.5)),
                      CSE_mean = mean(CSE),
                      CSE_sd = sd(CSE),
                      CSE_median=as.numeric(quantile(CSE,0.5)),
                      Ini_mean = mean(Ini),
                      Ini_sd = sd(Ini),
                      Ini_median=as.numeric(quantile(Ini,0.5)),
                      Sus_mean = mean(Sus),
                      Sus_sd = sd(PA),
                      Sus_median=as.numeric(quantile(Sus,0.5))
                      ) |> 
  pivot_longer(cols=1:30,
               names_prefix = c("pa","pad","bc","cpe","Ini",
                               "et","pfc","cse","Sus"),
               names_to= "SummaryStats",
               values_to="Values") |>
  mutate(Values=round(Values,2)) |> as.data.frame()
```

## Cronbach's alpha

We calculate Cronbach's alpha for the responses using the `cronbach.alpha()` function in the package `ltm`.

```{r, ca}
 responses <- gambling |>
   dplyr::select(starts_with(c("pa","pad","bc","cpe","Ini",
                               "et","pfc","cse","Sus"),ignore.case=F))

cronbach.alpha(responses,CI=T,standardized = T)
```

Overall Cronbach's alpha is estimated to be 0.883 (95% CI=(0.872,0.893)) higher than 0.70, which leads us to conclude that the instrument is acceptable.

We then look at the specific Cronbach's alphas for each construct.

### Perceived Advantage

```{r, pa}
gambling |> dplyr::select(starts_with("pa",ignore.case=F) &!starts_with("pad")) |> alpha()
```

### Perceived Disadvantage

```{r, pad}
gambling |> dplyr::select(starts_with("pad",ignore.case=F) ) |> alpha()
```

### Behavioral Confidence

```{r, bc}
gambling |> dplyr::select(starts_with("bc",ignore.case=F) ) |> alpha()
```

### Changes in Physical Environment

```{r, cpe}
gambling |> dplyr::select(starts_with("cpe",ignore.case=F) ) |> alpha()
```

### Entire Initiation Scale

```{r, inialpha}
gambling |> dplyr::select(starts_with(c("pa","pad","bc","cpe","Ini"),ignore.case=F)) |> alpha()
```

### Emotional Transformation

```{r, et}
gambling |> dplyr::select(starts_with("et",ignore.case=F) ) |> alpha()
```

### Practice for Change

```{r, pfc}
gambling |> dplyr::select(starts_with("pfc",ignore.case=F) ) |> alpha()
```

### Changes in the social environment

```{r, cse}
gambling |> dplyr::select(starts_with("cse",ignore.case=F) ) |> alpha()
```

### Overall sustenance

```{r, susalpha}
gambling |>  dplyr::select(starts_with(c("et","pfc","cse","Sus"),ignore.case=F)) |> alpha()
```

# CFA and SEM Analysis

## Initiation of quitting gambling

We now check for correlations between the items for initiation of quitting gambling.

```{r, corr}
# #| echo: false
 cormat <- gambling |>
   dplyr::select(starts_with(c("pa","pad","bc","cpe","Ini"),ignore.case=F)) |>   cor()

corrplot(cormat)
```

We now use the `lavaan` package to estimate a multi-group CFA by grouping each construct.

```{r,construct}
inimod <- 'pa =~ pa1 + pa2 +pa3 + pa4 + pa5
                pad =~ pad1 + pad2 + pad3 + pad4 + pad5
                bc =~ bc1 + bc2 + bc3 + bc4 + bc5
                cpe =~ cpe1 + cpe2 + cpe3
                ini=~ Ini'

CFAfit_ini <- cfa(inimod,data=gambling,
                  estimator="WLSMV")

CFAfit_ini |> summary(fit.measures=T,standardized=T)

semPaths(CFAfit_ini,what="diagram","std",layout="tree", rotation=2)

semPaths(CFAfit_ini,what="diagram","std",layout="tree",
          filetype="png",
         filename="CFA_ini",
         width=12,
         height=9,
         rotation=2)


```

The important fit measures are the following: RMSEA, SRMR, and CFI. We interpret the Robust RMSEA and CFI estimates to account for the Weighted Least Squares with Mean and Variance Adjustments (WLSMV) estimator. 

For an accetable fit, the following conditions should be satisfied: RMSEA values of $\leq$ 0.06, CFI values close to 1, and SRMR values less than 0.10. The overall model seems to satisfy the CFI and SRMR criteria, but not the RMSEA. However, there are some sources that say that RMSEA below 0.10 is still acceptable.


The matrix that shows the factor loadings are shown below in the lambda matrix

```{r, loadingini}
CFAfit_ini |> lavaan::inspect(what="std")

```

## Construct Validity (Convergent and Discriminant Validity)

We check convergent and discriminant validity by looking at the AVE (average variance extracted) for convergent validity and CR (composite reliability) for discriminant validity.

```{r,validity}
CFAfit_ini |> compRelSEM()
CFAfit_ini |> semTools::reliability()
CFAfit_ini |> AVE()
```

<!--# This is testing measurement invariance which we will not look at for this paper. -->

<!-- ## Configural Invariance -->

<!-- Let us now see if we have configural invariance between the non-gambling and gambling groups. -->

<!-- ```{r,config} -->
<!-- cfa.config <- cfa(inimod,data=gambling,group="Gambled",mimic="Mplus", -->
<!--                   estimator="MLM") -->
<!-- cfa.config |> summary(fit.measures=T,standardized=T) -->
<!-- cfa.config |> fitMeasures() -->
<!-- cfasem <- sem(inimod,data=gambling,group="Gambled") -->
<!-- lavaanPlot(model=cfasem,coefs = TRUE, stand = TRUE, sig = 0.05) -> lp -->
<!-- save_png(lp,"sem_ini.png") -->
<!-- semPaths(cfasem,"std",layout="tree") -->
<!-- ``` -->

<!-- The results show that the fit is good between the groups. CFI and TLI are close to 1,and the SRMR is close to 0.8. The RMSEA is slightly higher than 0.06. We can conclude that the two groups have the same factor structure. -->

<!-- ```{r,configvsgen} -->
<!-- compareFit(CFAfit_ini,cfa.config) |> summary() -->
<!-- ``` -->

<!-- We can compare this result with the model that does not consider groups. The AIC and BIC are significantly lower than the general model, which means the model that accounts for the recently gambled grouping performs better. Bear in mind that even if the CFI and TLI slightly decreased, it did not decrease significantly. The same can be said about the RMSEA and SRMR. -->

<!-- ### Construct validity -->

<!-- We now check validity through CR and AVE for the model with groupings: -->

<!-- ```{r,iniconfigvalidity} -->


<!-- cfa.config |> compRelSEM() -->
<!-- cfa.config |> semTools::reliability() -->
<!-- cfa.config |> AVE() -->
<!-- ``` -->

<!-- ## Metric Invariance -->

<!-- Now we are testing metric invariance, which sets the loadings to be equal. We then compare the fit between the configural and metric assumptions. -->

<!-- ```{r,metric} -->

<!-- cfa.metric <- cfa(inimod,data=gambling,group="Gambled",group.equal="loadings",estimator="MLM") -->

<!-- cfa.metric |> summary(fit.measures=T) -->

<!-- # cfa.metric |> fitmeasures() -->

<!-- # lavInspect(cfa.metric, -->

<!-- # "options")[c("estimator","test","meanstructure")] -->

<!-- #  -->

<!-- # lavInspect(cfa.config, -->

<!-- # "options")[c("estimator","test","meanstructure")] -->

<!-- compareFit(cfa.config,cfa.metric) |> summary() -->

<!-- ``` -->

<!-- Results show that the chi-square test is significant, which means that the metric invariance is not satisfied. This means that even if the groups have the same factor structures, the factor loadings are different across groups. This is understandable based on the nature of grouping (problem vs non-problem gamblers). There must be different sense of importance in their attitude towards quitting gambling. -->

<!-- ```{r, lavtestscore} -->

<!-- lavTestScore(cfa.config) -->

<!-- ``` -->

<!-- The significant score tests shows which questions between groups have different loadings. We can look at which relations/loadings are significantly different in the table below. -->

<!-- ```{r,parameters} -->

<!-- parTable(cfa.config) -->

<!-- ``` -->

## Sustenance of quitting gambling

We now check for correlations between the items for sustenance of quitting gambling.

```{r, corrsus}
 cormat <- gambling |> 
   dplyr::select(starts_with(c("et","pfc","cse","Sus"),ignore.case=F)) |>   cor()
 
 corrplot(cormat)
```

We now use the `lavaan` package to estimate a multi-group CFA by grouping each construct.

```{r,constructsus}
susmod <- 'et =~ et1 + et2 + et3
                pfc =~ pfc1 + pfc2 + pfc3
                cse =~ cse1 + cse2 + cse3
                sus=~ Sus'

CFAfit <- cfa(susmod,data=gambling,estimator="WLSMV")

CFAfit |> summary(fit.measures=T, standardized=T)


semPaths(CFAfit,"std",what="diagram",layout="tree", rotation=2)
semPaths(CFAfit,"std",what="diagram",layout="tree",
         filetype="png",
         filename="CFA_sus",
         width=12,
         height=9,
         rotation=2)
```

All fit measures indicate a good fit, with the CLI close to 1, RMSEA \< 0.06, and SRMR \< 0.05.

The matrix that shows the factor loadings are shown below in the lambda matrix

```{r, loadingsus}
CFAfit |> lavaan::inspect(what="std")

```

## Construct Validity (Convergent and Discriminant Validity)

We check convergent and discriminant validity by looking at the AVE (average variance extracted) for convergent validity and CR (composite reliability) for discriminant validity.

```{r,validitysus}

CFAfit |> compRelSEM()
CFAfit |> semTools::reliability()
CFAfit |> AVE()

```


<!-- ## Configural Invariance -->

<!-- Let us now see if we have configural invariance between the non-gambling and gambling groups. -->

<!-- ```{r,configsus} -->
<!-- cfa.config <- cfa(susmod,data=gambling,group="Gambled",mimic="Mplus", -->
<!--                   estimator="MLM") -->
<!-- cfa.config |> summary(fit.measures=T,standardized=T) -->
<!-- cfasem <- sem(susmod,data=gambling,group="Gambled") -->
<!-- lavaanPlot(model=cfasem,coefs = TRUE, stand = TRUE, sig = 0.05) -> lp_sus -->
<!-- save_png(lp_sus,"sem_sus.png") -->
<!-- semPaths(cfasem,"std",layout="tree") -->

<!-- ``` -->

<!-- The fit still remains acceptable after including groups, which means that both groups have the same factors in their model. -->

<!-- ### Construct Validity -->

<!-- We now check validity through CR and AVE for the model with groupings: -->

<!-- ```{r,susconfigvalidity} -->


<!-- cfa.config |> compRelSEM() -->
<!-- cfa.config |> semTools::reliability() -->
<!-- cfa.config |> AVE() -->
<!-- ``` -->

<!-- ## Metric Invariance -->

<!-- Now we are testing metric invariance, which sets the loadings to be equal. We then compare the fit between the configural and metric assumptions. -->

<!-- ```{r,metricsus} -->

<!-- cfa.metric <- cfa(susmod,data=gambling,group="Gambled",group.equal="loadings",estimator="MLM") -->

<!-- compareFit(cfa.config,cfa.metric) |> summary() -->

<!-- ``` -->

<!-- Results show that the chi-square test is not significant, which means that the metric invariance is satisfied. The new model where we constrained the loadings to be equal for both groups does not differ in terms of performance. This means that the two groups have the same factors and factor loadings.  -->

<!-- ## Scalar Invariance (strong invariance) -->

<!-- For scalar invariance, we also set the intercepts to be equal. -->

<!-- ```{r, scalarsus} -->

<!-- # Scalar model -->

<!-- cfa.scalar <- cfa(susmod, data = gambling,  -->

<!--                   estimator="MLM",group = "Gambled", group.equal = c("loadings","intercepts")) -->

<!-- cfa.scalar |> summary(fit.measures=T) -->

<!-- # Model comparison -->

<!-- compareFit(cfa.metric, cfa.scalar) |> summary() -->

<!-- ``` -->

<!-- There is no significant difference in chi-square values as well as the other fit measures, which means that the constructs in the sustenance aspect of quitting gambling is also scalar invariant.  -->

## T-test for different items

```{r, ttest}
gambling |> 
  summarize_at(vars(pa1:Sus),
               list(pvalue=~t.test(.~Gambled)$p.value)) |> 
  pivot_longer(cols=ends_with("value"),
               names_to = "Item",
               values_to = "p.value") |> 
  mutate(p.value=round(p.value,3)) |> 
  as.data.frame()
```

## Conclusions

We have established construct validity for our instrument as used in this data set. All Cronbach $\alpha$'s were calculated to be above 0.7, and the composite reliability values were all above 0.7 as well. Convergent validity was also shown by the average variance explained (AVE) where all of the AVE values were above 0.5.


# Added Analysis

## Changes in Physical Environment

```{r}
gambling |> dplyr::select(starts_with("cpe",ignore.case=F),Gambled) |> 
  pivot_longer(cols=cpe1:cpe3,names_to="CPE",values_to="Values") -> cpe
cpe |> 
  ggplot(aes(x=CPE,y=Values, fill=Gambled)) + geom_point(position="jitter") 
```
